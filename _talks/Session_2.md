---
title: "How We Model Language: From Word Embeddings to RNN to LSTM"
collection: talks
type: "Talk"
permalink: /talks/Session_2
venue: "Deep Learning Seminar"
date: 2024-10-20
location: "Xi'an Jiaotong University, Building C-206"
---

[More information here](https://space.bilibili.com/282545566/lists/4107286?type=season)

How can we model language? From word vectors to RNN to LSTM. What is the fitting ability of RNN? What are its limitations? What motivated the creation of LSTM and GRU? PyTorch implementation of RNN, GRU, and LSTM. What else can be improved?

